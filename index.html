<!DOCTYPE html>
<html>
  <head>
    <title>iCommand downpat Chromecast Receiver.</title>
    <style>
      * {
        padding: 0;
        margin: 0;
        border: 0;
        box-sizing: border-box;
      }
      body {
        width: 100vw;
        height: 100vh;
        overflow: hidden;
        padding: 20px 40px;
      }
      #content {
        height: 20vh;
        width: 100vw;
      }
      #youtube-src, #image-src, #video-tag {
        width: 100%;
        height: 100%;
        display: none;
        margin: auto;
      }
      #image-src {
        object-fit: cover;
      }
      #message {
        background-color: #000;
        color: #FFF;
        height: 80vh;
        width: 100vw;
        font-size: 20px;
        text-align: center;
        padding: 20px;
        margin: 0;
      }
      #msg {
        color: white;
        font-size: 20px;
      }
      span {
        color: white;
        font-size: 15px;
      }
    </style>
  </head>
  <body>
    <div id="msg"></div>
    <div id="content">
    </div>
    <div id="message"></div>
    <script src="//www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>
    <script>
      window.onload = function () {
        window.castReceiver = cast.framework.CastReceiverContext.getInstance();
        var namespace = 'urn:x-cast:com.downpat-test.cast';
        window.castReceiver.addCustomMessageListener(namespace, function (event) {
          var message = event.data;
          updateUI(message.type, message.src, message.text);
        });
        window.castReceiver.start({statusText: 'URL Cast starting...'});
      }
      function element (id) {
        return document.getElementById(id);
      }
      function imgError (error) {
        m(error ? ', ' + error.toString() : ', Image error!');
      }
      function speak (text) {
        try {
          var synth = window.speechSynthesis;
          if (text && synth && typeof SpeechSynthesisUtterance !== 'undefined') {
            var utterance = new SpeechSynthesisUtterance(text);
            synth.speak(utterance);
          }
        } catch (e) {}
      }
      var _msgs = '';
      function m (x) {
        _msgs += x;
        element('msg').innerText = _msgs;
      }
      function updateUI (which, src, text) {
        // element('msg').innerHTML = '</div><div>Type: ' + which + '</div><div>Text: ' + text + '</div><div>Src: ' + src + '</div>';
        // element('msg').innerHTML = '<div>Src: ' + src + '</div>';
        if (type === 'youtube') element('content').innerHTML = '<iframe id="youtube-src" width="560" height="315" src="' + src +'" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>'
        if (type === 'image') element('content').innerHTML = '<img id="image-src" src="' + src +'" onerror="imgError()" />';
        if (type === 'video') element('content').innerHTML = '<video id="video-tag" controls><source id="video-src" src="' + src +'" type="video/mp4">Your browser does not support the video tag.</video>';
        element('message').innerText = text;
        speak(text);
        window.castReceiver.setApplicationState('Now Playing: ' + src);
      }
    </script>
  </body>
</html>
