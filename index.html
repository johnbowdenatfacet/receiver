<!DOCTYPE html>
<html>
  <head>
    <title>iCommand downpat Chromecast Receiver.</title>
    <style>
      * {
        padding: 0;
        margin: 0;
        border: 0;
        box-sizing: border-box;
      }
      body {
        width: 100vw;
        height: 100vh;
        overflow: hidden;
        padding: 20px 40px;
      }
      #content {
        height: 80vh;
        width: 100%;
      }
      #youtube-src, #image-src, #video-tag {
        width: 100%;
        height: 100%;
        display: block;
        margin: auto;
      }
      #image-src {
        object-fit: cover;
      }
      #instructions {
        background-color: #000;
        color: #FFF;
        font-size: 25px;
        text-align: center;
        padding: 20px;
        width: 100%;
      }
      #instructions p {
        margin: 50px 0;
      }
      #message {
        background-color: #000;
        color: #FFF;
        height: 20vh;
        width: 100%;
        font-size: 25px;
        text-align: center;
        padding: 20px;
        margin: 0;
      }
    </style>
  </head>
  <body>
    <div id="content">
    </div>
    <div id="message"></div>
    <script src="//www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>
    <script>
      window.onload = function () {
        window.castReceiver = cast.framework.CastReceiverContext.getInstance();
        var namespace = 'urn:x-cast:com.downpat-test.cast';
        window.castReceiver.addCustomMessageListener(namespace, function (event) {
          var message = event.data;
          updateUI(message.type, message.src, message.text);
        });
        window.castReceiver.start({statusText: 'URL Cast starting...'});
      }
      function element (id) {
        return document.getElementById(id);
      }
      function speak (text) {
        try {
          if (!text) return;
          var synth = window.speechSynthesis;
          if (text && synth && typeof SpeechSynthesisUtterance !== 'undefined') {
            var utterance = new SpeechSynthesisUtterance(text);
            synth.speak(utterance);
          }
        } catch (e) {}
      }
      function updateUI (type, src, text) {
        var content = element('content');
        switch (type) {
          case 'waiting':
            content.innerHTML = '<div id="instructions"><p>downpat is awaiting instructions...</p></div>';
            break;
          case 'begin':
            content.innerHTML = '<div id="instructions"><p>Howto: <b>' + text + '</b></p><p>Ready to start? Use your device to issue commands.</p></div>';
            break;
          case 'finish':
            content.innerHTML = '<div id="instructions"><p>Howto: <b>' + text + '</b></p><p>Tutorial complete.</p></div>';
            break;
          case 'youtube':
            content.innerHTML = '<iframe id="youtube-src" width="560" height="315" src="' + src +'" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>';
            break;
          case 'image':
            content.innerHTML = '<img id="image-src" src="' + src +'" crossorigin="anonymous" />';
            break;
          case 'video':
            content.innerHTML = '<video id="video-tag" controls autoplay><source id="video-src" src="' + src +'" type="video/mp4">Your browser does not support the video tag.</video>';
        }
        var message = element('message');
        if (['waiting', 'begin', 'finish'].indexOf(type) < 0) message.innerText = text;
        else message.innerText = '';
        speak(text);
        window.castReceiver.setApplicationState('Now Playing: ' + src);
      }
    </script>
  </body>
</html>
